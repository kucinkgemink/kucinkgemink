# Impor library yang diperlukan
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import (
    accuracy_score,
    confusion_matrix,
    classification_report,
    precision_score,
    recall_score,
    f1_score,
)
import joblib
import os
from tabulate import tabulate

# --- Konfigurasi ---
TRAINING_DATA_FILE = 'dataset_knn5'
TEST_SIZE = 0.3
RANDOM_STATE = 101
MODEL_FILE = 'knn_model.joblib'
SCALER_FILE = 'scaler.joblib'
PARAM_GRID = {
    'n_neighbors': range(1, 21),
}
CV = 5


def load_and_split_data():
    try:
        df = pd.read_csv('dataset_knn5.csv')

        required_columns = {'co', 'co2', 'pm2.5', 'pm10', 'kategori'}
        if not required_columns.issubset(df.columns):
            raise ValueError(f"CSV must contain columns: {required_columns}")

        # Konsisten pakai huruf kecil
        df['kategori'] = df['kategori'].astype(str).str.lower().str.strip()
        df = df[df['kategori'].isin(['baik', 'sedang', 'buruk'])]

        # Fitur hanya numerik
        feature_columns = ['co', 'co2', 'pm2.5', 'pm10']
        df = df.dropna(subset=feature_columns + ['kategori'])

        if df.empty:
            raise ValueError("Data kosong setelah pembersihan. Periksa file CSV.")

        X = df[feature_columns].values
        y = df['kategori'].map({'baik': 0, 'sedang': 1, 'buruk': 2})

        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE
        )

        # Scaling
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        return X_train_scaled, X_test_scaled, y_train, y_test, scaler

    except Exception as e:
        print(f"Error loading/splitting data: {e}")
        return None, None, None, None, None

def train_and_tune_knn(X_train, y_train):
    knn = KNeighborsClassifier(metric='euclidean')
    grid_search = GridSearchCV(knn, PARAM_GRID, cv=CV, scoring='accuracy', verbose=2)
    grid_search.fit(X_train, y_train)

    print("Best parameters found:", grid_search.best_params_)
    print("Best cross-validation score:", grid_search.best_score_)

    return grid_search.best_estimator_


def evaluate_model(knn_model, X_test, y_test):
    y_pred = knn_model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)

    conf_matrix = confusion_matrix(y_test, y_pred)
    class_report = classification_report(
        y_test, y_pred, target_names=['baik', 'sedang', 'buruk'], zero_division=0
    )

    print(f"\nAccuracy: {accuracy:.4f}")
    print("Confusion Matrix:\n", conf_matrix)
    print("\nClassification Report:\n", class_report)

    table_data = [
        ["Metrik", "Nilai"],
        ["Accuracy", f"{accuracy:.4f}"],
        ["Precision (weighted)", f"{precision:.4f}"],
        ["Recall (weighted)", f"{recall:.4f}"],
        ["F1-Score (weighted)", f"{f1:.4f}"],
    ]
    print("\nEvaluation Metrics Table:")
    print(tabulate(table_data, headers="firstrow", tablefmt="grid"))

    return accuracy


def save_model_and_scaler(model, scaler, model_path, scaler_path):
    try:
        joblib.dump(model, model_path)
        joblib.dump(scaler, scaler_path)
        print(f"Model saved to {model_path}")
        print(f"Scaler saved to {scaler_path}")
    except Exception as e:
        print(f"Error saving model/scaler: {e}")


def main():
    X_train_scaled, X_test_scaled, y_train, y_test, scaler = load_and_split_data()
    if X_train_scaled is not None:
        best_knn_model = train_and_tune_knn(X_train_scaled, y_train)
        print("\n--- Evaluating on Test Set ---")
        evaluate_model(best_knn_model, X_test_scaled, y_test)
        save_model_and_scaler(best_knn_model, scaler, MODEL_FILE, SCALER_FILE)
    else:
        print("Model training failed due to data loading/processing issues.")


if __name__ == '__main__':
    main()


